% \subsection{Limitations \& Solutions}

The Wmatrix tag wizard toolchain was originally designed and developed to run on commodity computing hardware in a batch processing fashion.  Because of this design, the toolchain respects a number of common limits that apply to desktop computers (for example, low memory limits) and attempts to exploit other resources that are available in abundance (fast sequential file I/O).
Many of these properties do not transfer to larger clusters, and a number of changes had to be made in order to align the processing stages with the resources available on the HEC system.


\paragraph{File Access}
The Wmatrix toolchain makes extensive use of small output and intermediate files during operation.  This incurs a significant performance overhead when used with filesystems that are typical in high-end distributed systems, which often use large block sizes, carry metadata for versioning and redundancy, or are accessible only over network links.
For this particular process, each input file causes creation of eleven intermediate and output files.  When parallelised, the number of concurrent operations performed on a shared filesystem is thus greatly magnified.
A combination of these two design characteristics and the organisation of the corpus itself (stored as many small files) proved to be a severe limitation during the tagging operation as parallel instances soon overwhelmed the 500MBps bandwidth limit on the storage system used.
The solution to this problem effected changes to the whole toolchain.  First, the corpus was archived such that each day was contained within a single \mon{tar} archive.  This input file could then be copied with a single operation from the shared drive.
The toolchain was modified to extract this input data into a temporary folder, stored on the local disk of the compute node upon which it was running.
Following execution, all output was again archived using \mon{tar} and copied back to the shared drive.  This process necessitated a further stage after processing where the output data would be checked and extracted, which was performed after downloading data from the HEC.


\paragraph{Memory Size}
The toolchain used was originally built to run on computers with modest memory requirements.  As such, it uses temporary files for some of its larger volumes of working data, and conflates arrays at runtime in order to minimise memory usage.
Without significant re-engineering we were unable to exploit the relatively high 24GB memory space on each of the compute nodes.  
%As mentioned above, however, this memory space was used instead to mitigate the I/O bandwidth required of shared storage systems.




% If we need to further reduce words then this could be thinned out or commented out

\paragraph{Indexing and Co-ordination}
Due to the distribution method used to mitigate file access rate limits, the tagging toolchain was operating on data checked out of a central store.  As such, a system of co-ordination was necessary to prevent tasks colliding.
This was accomplished by using a flatfile, centrally stored and accessed once per batch, that contained a list of input archives and their corresponding output directories.  This list was split line-by-line using \mon{sed}, and a range of input files was chosen based on the `job ID' environment variable exposed by the scheduling system.  This ensured that a unique range of files were taken for each job, and no task relied on the output from another.
The number of input archives tagged per job was chosen to balance scheduling overheads with the need to `smooth out' file access and ensure that any failures did not affect large areas of the corpus.  Ultimately, each job was run using 20 input directories, chosen to take 30 minutes using average input files.


% I think this paragraph could be commented out completely to save words
% let's retain stuff for the final paper if accepted

\paragraph{Scheduling Overhead}
The overhead incurred by a shared scheduling system is significant compared to a typical process creation task.  This was compounded by the co-ordination method above, which required multiple processes to run and multiple I/O operations to copy data onto the compute node.
In practice, running 2230 jobs, this overhead proved to be insignificant when compared to the time taken moving input data onto compute nodes.
% As mentioned above, this problem was largely solved by tagging multiple directories within a single batch, re-using each compute node many times before copying results back.





% Commented out for now, let's include in future work if there is space

% \paragraph{Per-node Parallelism}
% Each compute node on the HEC is furnished with 8-12 processor cores.  Wmatrix itself does not take advantage of this parallelism, and no effort was made to do so in the job dispatch scripts.  As such, this remains the largest untapped source of further performance.


% \begin{itemize}
%     \item Small files (filesystem overhead)
%         \begin{itemize}
%             \item Input files [tarred, stored in RO storage]
%             \item Temp files and toolchain comms [on nodes]
%             \item Output file storage [tarred, stored on shared disk after tarring]
%             \item 'you'll also need to think about total I/O bandwidth; bear in mind that we have a maximum capacity of 500 MB/s across the cluster' -- MP
%            \item "The corpus gets ~8.2 times bigger when processed (including original data), so any result is going to sum to around 400 GB in 7,545,102 small files." -- me
%         \end{itemize}
%     \item Small jobs (job overhead)
%         \begin{itemize}
%             \item Batching using ID numbers
%             \item Scheduling to distribute load (many jobs, composite job thing)
%         \end{itemize}
%     \item Co-ordination of parallel tasks
%         \begin{itemize}
%             \item Use of a pre-built index
%             \item batches of fixed size, job ID computes offset
%         \end{itemize}
% \end{itemize}


% I've commented out this whole subsection for now
% We can add stuff back in if there is space

% \subsection{Final Method}
% The final method involved three main stages:

% \begin{enumerate}
%     \item Batching of input data for each tagging job;
%     \item Processing using scheduled batch jobs on the HEC cluster;
%     \item Validation and extraction.
% \end{enumerate}


% \paragraph{Preprocessing}
% This was performed prior to uploading data onto the cluster itself, and involved producing an uncompressed \mon{tar} archive of each day's corpus data.

% After these data were batched, they were uploaded to the cluster and an index was generated listing each archive in a one-line-per-file format.  The position of this index was included in the batch processing script passed to the scheduler.


% \paragraph{Processing}
% Jobs proceeded first by identifying input archives and copying them to a working directory within the assigned compute node.  This working directory was mounted in memory, yielding minor performance improvements and utilising some of the unused space there\footnote{The toolchain was designed in the 1990s, and uses little memory compared to the compute node's limits or even a modestly provisioned modern desktop system.}.

% From there, a script iterated through each of the input files, running one instance of the toolchain before archiving the results and placing them in an output directory.

% After the batch had completed, each output directory was itself archived and placed in a copy of the input corpus' structure on shared storage.  This system reduced the number of I/O operations performed on shared storage to roughly 24 move or copy operations per job.

% Using 20 days' data per job resulted in 2230 total jobs, each tuned to last roughly 30 minutes.


% \paragraph{Postprocessing}
% After the output structure was downloaded from the high performance cluster, a script was run in order to verify that:

% \begin{itemize}
%     \item All files were processed;
%     \item The number of files in each output archive was correct;
%     \item Filesizes are nonzero.
% \end{itemize}

% Additionally, the standard error logs were inspected to identify any failed tagging runs.  This resulted in three failed files, each of which proved to fail when run manually and remained untagged.




% 
% \begin{itemize}
%     \item Corpus pre-tarred into daily runs so as to avoid filesize issues and problems with multiple-directory structure
%     \item Corpus stored in read-only space due to size
%     \item Everything compiled in ~/.local directory on server, batch scripts set up for toolchain in new shell
%     \item Produce directory listing of input file groups
%     \item Batch file
%         \begin{itemize}
%             \item Computes batch size from batch ID ((id - 1) * batchsize) to (id * batchsize)
%             \item Duplicates n items from directory tree in the working compute node (20 in practice)
%             \item extracts everything
%             \item Runs pipeline over each file
%             \item Archives results
%             \item Archives all of those results to produce a large file for storage on panasas shelf
%             \item Copies results to shared result tree
%             \item Deletes compute node working data
%             \item Stores stdout/stderr in common location with batch ID
%         \end{itemize}
%     \item Output structure taken off HEC
%     \item Validation script tests:
%         \begin{itemize}
%             \item output files exist
%             \item The right number of files is in the output/input tars
%             \item File sizes are nonzero
%         \end{itemize}
% \end{itemize}



