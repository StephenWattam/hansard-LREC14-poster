    This poster describes experiences processing the two-billion-word Hansard corpus using a fairly standard NLP pipeline on a high performance cluster.  Herein we report how we were able to parallelise and apply a ``traditional'' single-threaded batch-oriented application to a platform that differs greatly from that for which it was originally designed. We start by discussing the tagging toolchain, its specific requirements and properties, and its performance characteristics.  This is contrasted with a description of the cluster on which it was to run, and specific limitations are discussed such as the overhead of using SAN-based storage. We then go on to discuss the nature of the Hansard corpus, and describe which properties of this corpus in particular prove challenging for use on the system architecture we used. The solution for tagging the corpus is then described, along with performance comparisons against a na\"{i}ve run on commodity hardware.  We discuss the gains and benefits of using high-performance machinery rather than relatively cheap commodity hardware. Our poster provides a valuable scenario for large scale NLP pipelines and lessons learnt from the experience.


% My collided edit:
%
% This poster describes experiences gained in adapting the USAS semantic tagger for use on the Lancaster University high-end computing (HEC) cluster.  We describe the process of tagging the Hansard corpus, comprising 2.2 billion words, by parallelising the existing toolchain: a ``traditional'' single-threaded, batch-oriented system originally designed for execution on low-resource desktop machines.\\
%     We start by discussing the tagging toolchain, its specific requirements and properties, and its performance characteristics.  This is contrasted with a description of the cluster on which it was to run, and specific limitations are discussed, such as the overheads involved in scheduling jobs and accessing SAN-based storage arrays.\\
%     The structure of the Hansard corpus is then described, and it is assessed to identify which aspects prove challenging for use on the cluster.  We describe the solution found, and compare its performance to that of a conventional desktop system in order to evaluate the efficacy of the parallelisation effort.
%     We conclude that many data sets and toolchains may benefit only a little from parallelisation due to the development overhead required, but that this particular data set benefitted greatly from the increased performance high-performance computing hardware affords.
% 



